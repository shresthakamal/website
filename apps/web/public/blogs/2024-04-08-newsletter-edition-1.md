---
layout: post
title: LLM News and Articles Weekly Digest - April 8, 2024
date: 2024-04-08 15:09:00
description: Weekly Updates on advancements in LLMs 
categories: nlp llm genai newsletter weeklydigest
disqus_comments: true
related_posts: true
---

![Banner](/assets/newsletter/april-8/1.jpg)

## Latest News


1. Start ChatGPT instantly without having to sign up. "There are many benefits to creating an account including the ability to save and review your chat history, share chats, and unlock additional features like voice conversations and custom instructions. For anyone that has been curious about AI's potential but didn't want to go through the steps to set-up an account, start using ChatGPT today." [[Source]](https://openai.com/blog/start-using-chatgpt-instantly)

2. Princeton SWE-agent gets 12.29% on SWE-bench (ODD Devin got 13.84) : SWE-agent is our new system for autonomously solving issues in GitHub repos + it's open source [[Tweet]](https://twitter.com/jyangballin/status/1775114444370051582)

3. OpenAI's Sora just made its first music video and it's like a psychedelic trip : The ambient track coupled with the footage results in a uniquely ethereal experience. It's half pleasant and half unsettling. [[Youtube]](https://www.youtube.com/watch?v=f75eoFyo9ns)

4. Cohere - CommandR PLUS - 104B RAG optimized Sonnet competitor. [[Tweet]](https://twitter.com/aidangomez/status/1775878606108979495)

5. OpenAI expands its custom model training program : OpenAI's Custom Model program now offers assisted fine-tuning and custom-trained models, catering to enterprise needs for tailored generative AI solutions. [[Source]](https://techcrunch.com/2024/04/04/openai-expands-its-custom-model-training-program/)

6. Lambda Announces $500M GPU-Backed Facility to Expand Cloud for AI : Lambda, led by COO Mitesh Agrawal, introduces a novel financing method for deploying NVIDIA GPUs, removing barriers for AI startups. The asset-based structure leverages GPU cash flows, enabling on-demand cloud access without lengthy contracts. With over 100,000 sign-ups, Lambda Cloud supports NVIDIA GPU deployments for training and inferencing generative AI models. [[Source]](https://www.businesswire.com/news/home/20240402148086/en/Lambda-Announces-500M-GPU-Backed-Facility-to-Expand-Cloud-for-AI)

7. Groq lands function calling : Tool Use/Function Calling (beta) for Groq API is now available! This highly anticipated feature allows models available on GroqCloud to take user-defined functions as inputs and generate structured output to invoke them from external tools / codebases. [[Source]](https://console.groq.com/docs/tool-use?hss_channel=tw-842860575289819136#models)

8. Anthropic adds function calling support : Tool use is now available in beta to all customers in the Anthropic Messages API, enabling Claude to interact with external tools using structured outputs.[[Source]](https://docs.anthropic.com/claude/docs/tool-use)

<br>

## Articles

1. [Open/Close source LLM](https://xtimes.medium.com/open-close-source-llm-3a4b6d100115)

2. [The Perfect Prompt: Prompt Engineering Cheat Sheet](https://medium.com/@maximilian.vogel/the-perfect-prompt-prompt-engineering-cheat-sheet-d0b9c62a2bba)

3. [The ABC of LLMs: A Beginner's Guide](https://medium.com/@adeelsarwarblog/the-abc-of-llms-a-beginners-guide-ea3075748cd0)

4. [RAG Implementations Are Becoming More Agent-Like](https://cobusgreyling.medium.com/rag-implementations-are-becoming-more-agent-like-82423ffe1ea1)

5. [Mixtral AI generated comment to US regulators about Open Models](https://www.regulations.gov/comment/NTIA-2023-0009-0228)

6. [Introducing Buddhi: Open-Source Chat Model with a 128K Context Window](https://medium.aiplanet.com/introducing-buddhi-open-source-chat-model-with-a-128k-context-window-06a1848121d0)

<br>


## Papers and Repositories

1. Google presents Noise-Aware Training of Layout-Aware Language Models [[Paper]](https://arxiv.org/abs/2404.00488)

2. Deepmind - Mixture of Depth paper : This work introduces a method where transformers dynamically allocate compute resources across input sequences, optimizing allocation for different layers. By capping token participation in computations at each layer, it achieves predictable yet context-sensitive compute expenditure, resulting in efficient models matching baseline performance with fewer FLOPs and faster training. [[Paper]](https://arxiv.org/abs/2404.02258)

3. Jamba whitepaper is out! : The whitepaper details our in-depth ablations on this novel hybrid SSM-Transformer architecture, and how we chose to interleave Mamba, Transformer and MoE. [[Paper]](https://arxiv.org/abs/2403.19887)

4. Show HN: I built a tool to crowdsource and share LLM experiments [[Github]](https://github.com/Filimoa/open-parse)

5. Octopus v2: On-device language model for super agent : It introduces a method for on-device models with 2 billion parameters to outperform GPT-4 in accuracy and speed, reducing context length significantly. Compared to other models, this improves latency by 35 times, suitable for real-world applications on edge devices. [[Paper]](https://arxiv.org/abs/2404.01744)

6. Representation Finetunning (ReFT): A Powerful, Parameter-Efficient, and Interpretable way of fine-tuning [[Github]](https://github.com/stanfordnlp/pyreft)


<br>

Thank you for reading ! 

If you have any comments or feedback, please do comment. You can find me on [[Linkedin]](https://www.linkedin.com/in/shresthakamal/).

Find the medium post here: https://shresthakamal.medium.com/llm-news-and-articles-weekly-digest-april-8-2024-466fe73f6233 