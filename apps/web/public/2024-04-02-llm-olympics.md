---
layout: post
title: LLM OLYMPICS 2024
date: 2024-03-01 15:09:00
description: This blog is an attempt to mention most of the major developments in the LLM race, as the world is calling it, the center of the new tech evolution. 
categories: nlp llm genai openai claude anthropic
disqus_comments: true
related_posts: true
---


<style>
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>

<p style="text-align:justify">
This blog is an attempt to mention most of the major developments in the LLM race, as the world is calling it, the center of the new tech revolution. You will soon find out that it's not just a running race but rather a leaping race forward. Buckle up and let us begin.
<br><br>
<i>Please feel free to correct me in any way, I am also learning and writing as I go. Looking forward to your constructive feedback.</i></p>
<br>

<div>
  <div>
    <img src="/assets/blogs/llm-olympics/B1.png" alt="Snow" style="width:80%">
  </div>
  <br>
  <p style="text-align:center">
  <i>Figure 1: (Left) OpenAI’s Sora generating video of a woman walking down the streets of Tokyo, (Right) Claude 3 Model family</i>
  </p>
</div>



Starting with ChatGPT, the generative AI frenzy has triggered global wide accessibility of LLMs and its emergent capabilities. Now, not only being limited to the tech giants but rather, it has already started being incorporated to numerous consumers facing enterprise solutions/products making things ease, efficient, instant and diverse with retrieving documents from piles, generating interactive content, analyzing data, inferring business decisions and even replacing humans.

<b>“Compute, Not Fiat or Bitcoin, Will Be The 'Currency of the Future' and will be the most expensive commodity, Says Sam Altman as Nvidia's Jensen Huang Highlights $100 Trillion AI Opportunity”.</b> 

<p style="text-align:justify">
It is no longer the case that we are limited to text, as the past was, the advancement includes ALL the data you can ever imagine. With multimodality, think about images, videos, tables, graphs, audios, flowcharts, designs, networks, graphs, everything can be processed, understood, referenced, retrieved, analyzed and generated that are far more superior to what a human ever will be able to. Think about readings and understanding pages of books, generating software with thousands of lines of code, generating diverse identities with images, sketches & 3D avatars, creating real experiences, scenes, movies with videos, expressing sentiments with audios and now potentially exploring the physical worlds with robots, all is not just possible, but is already being done, and is leaping forward like never.
</p>

<div>
  <div>
    <img src="/assets/blogs/llm-olympics/B2.png" alt="Snow" style="width:80%">
  </div>
  <br>
  <p style="text-align:center">
  <i>Figure 2: The evolutionary tree of modern LLMs from "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"</i>
  </p>
</div>

<p style="text-align:justify">
Will 2024 be the year when LLMs surprise human intelligence, break the MMLU benchmark, undergraduate level knowledge, from 86.85% with Claude-3 to all the way 100% or will 2024 be the year where humanity finally gets the wake-up call and a taste of the future to say Stop it, we have had enough? When do we say, we need a pause because it is not going to stop.
<br>
OpenAI is already planning for Artificial General Intelligence (AGI), Microsoft and Google have already started integrating all its suite's products with LLMs, Elon Musk at X is pouring billions of dollars into its own, businesses all around the world have a LLM based revenue and subscription model, we already have an AI software developer among us and so much more. The only question for me is, I have seen enough, what else will surprise me more? But just after me saying that, I will be in the coming days, very soon.

</p>

<div>
  <div>
    <img src="/assets/blogs/llm-olympics/B4.png" alt="Snow" style="width:80%">
  </div>
  <br>
  <p style="text-align:center">
  <i>Figure 3: Comparison of the Claude 3 models to those of our peers on multiple benchmarks</i>
  </p>
</div>


I think that it will be enough of me contextualizing the hyperbolic advancements in LLMs, rather we in this blog we will look at the timelines of the developments of LLMs recently from our participants of the race.
Introducing the Olympics 2024 of bigger, better and human-like LLM we have: OpenAI/Microsoft, Google (DeepMind), Anthropic, Amazon, Mistral, Cohere, Hugging face, NVIDIA, Inflection, Baidu, now X (Twitter) and sometime later Apple.

I will structure the announcements, facts, features, news and anything I can find in the form of a timeline as shown below, almost all are referenced below for more further information if you need.

<b>You can find the complete timeline here : <a href="https://excalidraw.com/#json=bxBZKnUIfYczErzsrZd25,zLfaG7AyUzSjVOnZDBHVrg">LLM OLYMPICS 2024</a> as well as. </b>
<br><br>
<img src="/assets/blogs/llm-olympics/LLM OLYMPICS.svg"/>

<!-- <table style="height: 448px; width: 807px;">
<tbody>
<tr style="height: 23px;">
<td style="width: 148.672px; height: 23px;"><strong>&nbsp;[2017]&nbsp;</strong></td>
<td style="width: 656.328px; height: 23px;">&nbsp;</td>
</tr>
<tr style="height: 63px;">
<td style="width: 148.672px; height: 63px;">
<p align="center">[X]</p>
</td>
<td style="width: 656.328px; height: 63px;">
<p align="justify">Transformer Model Architecture, Attention is all you need <em>(The Almighty Supreme)</em></p>
<p align="justify">&ldquo;<em>LSTMs are dead, Long Live Transformers&rdquo;</em></p>
</td>
</tr>
<tr style="height: 53.5px;">
<td style="width: 148.672px; height: 53.5px;">&nbsp;
<p align="justify"><strong>[2018]</strong></p>
</td>
<td style="width: 656.328px; height: 53.5px;">&nbsp;</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[06]&nbsp;</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI Generative Pre-Trained Transformers &ndash; 1.5B params</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;"><p align="center">[08]&nbsp;</p></td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Google&rsquo;s Bidirectional Encoder Representations for Transformers (BERT)</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;"><p align="center">[02]&nbsp;</p></td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI GPT-2 with 8.3B params, <em>Generates human-like texts</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;"><p align="center">[03]&nbsp;</p>&nbsp;</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Baidu Enhanced Representation through knowledge Integration (ERNIE) with 4.5B params</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">
<p align="justify"><p align="center">[06]&nbsp;</p></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Microsoft invest $1Billion in OpenAI</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><strong>[2020]</strong></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><p align="center">[05]&nbsp;</p></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI GPT-3 with 175B params, <em>largest ever language model</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><strong>[2021]</strong></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><p align="center">[01]&nbsp;</p></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI introduces DALL-E with 12 B params, <em>Generate images from text</em></p>
</td>
</tr>
<tr style="height: 117px;">
<td style="width: 148.672px; height: 117px;">
<p align="justify"><p align="center">[05]&nbsp;</p></p>
</td>
<td style="width: 656.328px; height: 117px;">
<p align="justify">Google Introduces LaMDA, <em>intended for dialogue-based agents</em><br /> <span style="font-family: Aptos, serif;"><span style="font-size: small;"><span lang="en-US"><em>Google plans to integrate LaMDA into its main search portal, its voice assistant, and Workplace, its collection of cloud-based work </em></span></span></span> <span style="font-family: Aptos, serif;"><span style="font-size: small;"><span lang="en-US"><em>software that includes Gmail, Docs, and Drive. But the eventual goal, said Pichai, is to create a conversational interface that allows </em></span></span></span> <span style="font-family: Aptos, serif;"><span style="font-size: small;"><span lang="en-US"><em>people to retrieve any kind of information&mdash;text, visual, audio&mdash;across all Google&rsquo;s products just by asking</em></span></span></span><span style="font-family: Aptos, serif;"><span style="font-size: small;"><span lang="en-US">.</span></span></span></p>
</td>
</tr>
<tr style="height: 33px;">
<td style="width: 148.672px; height: 33px;">
<p align="justify"><p align="center">[06]&nbsp;</p></p>
</td>
<td style="width: 656.328px; height: 33px;">
<p align="justify">Github introduces Copilot, AI pair-programmer for Coding</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><strong>[2022]</strong></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[01]&nbsp;</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI&rsquo;s InstructGPT, <em>a model better at following instructions and less likely to hallucinate</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[04]</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Google introduces PaLM with 540B params</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[07]</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Huggingface introduces BLOOM 176B params, <em>beating the previous largest model</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[11]</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">OpenAI Introduces ChatGPT, generative AI chatbot</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><strong>[2023]</strong></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[01]</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Microsoft invests $10 billions more on OpenAI (rumoured)</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="center">[02]</p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Google introduces BARD, Meta Introduces LLaMA, Microsoft includes AI in its search engine, Bing</p>
</td>
</tr>
<tr style="height: 113px;">
<td style="width: 148.672px; height: 113px;">&nbsp;
<p align="center">[03]</p>
</td>
<td style="width: 656.328px; height: 113px;">&nbsp;
<p align="justify">OpenAI introduces APIs for developers, launches GPT-4, <em>likely a trillion params multimodal model</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">Amazon introduces its LLM, BedRock, NVIDIA showcases NEMO</p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify"><em>-------------------------------------- Quantization Techniques -------------------------------------------</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;<p align="center">[05]</p></td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">Falcon tops OpenLLM Leaderboard with 40B params</p>
</td>
</tr>
<tr style="height: 133px;">
<td style="width: 148.672px; height: 133px;"><p align="center">[07]</p>&nbsp;</td>
<td style="width: 656.328px; height: 133px;">&nbsp;
<p align="justify">Anthropic Claude 2, <em>200K token context length</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">Meta releases LLaMA 2 with 7, 13, 70B params, <em>includes commercial license and 40% better performance</em></p>
</td>
</tr>
<tr style="height: 133px;">
<td style="width: 148.672px; height: 133px;">&nbsp;<p align="center">[12]</p></td>
<td style="width: 656.328px; height: 133px;">&nbsp;
<p align="justify">Mixtral introduces 8x7B, <em>introduces mixture of models (MoEs) in its architecture</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">Microsoft introduces Phi-2 with 2.7B params, <em>surprises with the power small LLMs, beats Mixtral, LLaMA2</em></p>
</td>
</tr>
<tr style="height: 53px;">
<td style="width: 148.672px; height: 53px;">&nbsp;
<p align="justify"><strong>[2024]</strong></p>
</td>
<td style="width: 656.328px; height: 53px;">&nbsp;
<p align="justify">&nbsp;</p>
</td>
</tr>
<tr style="height: 303px;">
<td style="width: 148.672px; height: 303px;">&nbsp;
<p align="center">[02]</p>
</td>
<td style="width: 656.328px; height: 303px;">&nbsp;
<p align="justify">OpenAI introduces Sora, <em>text to video model capable of generating realistic and imaginative scenes</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">Google introduces Gemini 1.5 (pro) with MoE architecture, <em>context size of up to 10M tokens (GPT4 has 128K),</em></p>
<p align="justify"><em>can incorporate 1 hour of video, 11 hours of audio, &gt;30K lines of code, &gt;700K words</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">Microsoft publishes the paper &ldquo;The Era of 1-bit LLMs&rdquo;, <em>representing weight parameters as either {-1, 0,1} not floating-point numbers (16 bits)</em></p>
<p align="justify">&nbsp;</p>
<p align="justify">OpenAI collaborates with FigureAI, <em>to develop humanoid robots with $675B params in Series B funding</em></p>
</td>
</tr>
<tr style="height: 231px;">
<td style="width: 148.672px; height: 231px;"><p align="center">[03]</p>&nbsp;</td>
<td style="width: 656.328px; height: 231px;">&nbsp;
<p align="justify">Cognition Labs introduces world&rsquo;s first fully autonomous AI Software Developer called Devin, <em>capable of </em><br /> <em>developing an entire software itself, </em><span style="font-family: Aptos, serif;"><span style="font-size: medium;"><span lang="en-US"><em>and setting a new state of the art on the SWE-bench coding</em></span></span></span></p>
<p align="justify">&nbsp;</p>
<p align="justify">Anthropic introduces Claude-3 (Opus (most intelligent), Sonnet and Haiku) with 175B params, <em>beating all </em> <em>previous models in almost all evaluation metrics of text</em></p>
<p align="justify"><em>XAI (previously twitter AI) </em>open sources Grok-1, 314 B params with MoE architecture<em>, doesn&rsquo;t beat all the </em> <em>models but Elon Musk is just getting started.&nbsp;</em><span style="font-family: Aptos, serif;"><span style="font-size: medium;"><span lang="en-US"><em>A unique and fundamental advantage of Grok is that it has real-time knowledge of the world via the X platform.</em></span></span></span></p>
</td>
</tr>
<tr style="height: 193px;">
<td style="width: 148.672px; height: 193px;"><p align="center">[...]</p>&nbsp;</td>
<td style="width: 656.328px; height: 193px;">&nbsp;
<p align="justify">OpenAI is rumored to be not training GPT-5 and<em> expanding GPT-4 by connecting it to Internet and more...</em></p>
<p align="justify"><br /> <em>Sam Altman says that this technology affects everyone, so it is important to involve everyone in discussions.</em><br /><br /></p>
<p align="justify">Google and Apple might collaborate to add Gemini to iPhone, Samsung Galaxy and Pixel phones</p>
</td>
</tr>

</tbody>
</table> -->
<!-- DivTable.com -->


**The DeFacto understanding or the general belief in the world of LLMs is that the larger the model size, the bigger the model means the better the model. So, it can be well predicted that the athletes in this race will continue beefing up their flagship models with even more parameters, instructions and use cases.** 

What does it mean for humanity to already start developing models better than GPT-4 or even GPT-5 when we still don’t understand how GPT-4 works and what it does?  How will the world evolve and how will the job market shape itself, when LLMs are connected to the internet and proxy the users on their behalf, who will we be talking to? What skills will be relevant and what won’t?

LLM generating text and amusing images, might be only a tiny bit of what's really important, what if LLMs are able to teach themselves (self-learning capabilities), learn to differentiate better from good, and apply betterness in itself? Or AI is still very expensive in resources and won’t change much? We are just hallucinating.


With all these, let us not talk about ethical and privacy issues, we will be here all day.



Nevertheless, we are all watching with our bated breath.

<br>

_Thank you for reading till here, Much Appreciated._

<br>

### References


1. Announcing Grok, https://x.ai/blog/grok 
2. Better language models and their implications, https://openai.com/research/better-language-models 
3. Language models are few-shot learners, https://openai.com/research/language-models-are-few-shot-learners
4. Evaluating large language models trained on code, https://openai.com/research/evaluating-large-language-models-trained-on-code 
5. WebGPT: Improving the factual accuracy of language models through web browsing, https://openai.com/research/webgpt 
6. Mixtral of experts, https://mistral.ai/news/mixtral-of-experts/ 
7. 2024 Outlook for Language Models by Ubaid Dhiyan, https://www.linkedin.com/pulse/2024-outlook-language-models-ubaid-dhiyan-t2uoc/ 
8. The Claude 3 Model Family: Opus, Sonnet, Haiku, https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf 
9. Video generation models as world simulators, https://openai.com/research/video-generation-models-as-world-simulators 
10.  Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context, https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf 
11. The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits, https://arxiv.org/abs/2402.17764 
12. Introduction to Quantization cooked in 🤗 with 💗🧑‍🍳, https://huggingface.co/blog/merve/quantization 
13. This week, @xAIwill open source Grok, https://twitter.com/elonmusk/status/1767108624038449405 
14. Overview of LLM Quantization Techniques & Where to Learn Each of Them?, https://yousefhosni.medium.com/overview-of-llm-quantization-techniques-where-to-learn-each-of-them-0d8599acfec8 
15. Our next-generation model: Gemini 1.5, https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/ 
16. bistandbytes 4-bit quantization blogpost - This blogpost introduces 4-bit quantization and QLoRa, an efficient finetuning approach. 
17. Merve's blogpost on quantization - This blogpost provides a gentle introduction to quantization and the quantization methods supported natively in transformers.
18. OpenAI's GPT-5 release could be as early as this summer, https://sea.mashable.com/tech/31750/openais-gpt-5-release-could-be-as-early-as-this-summer 
19. The History of Large Language Models, https://synthedia.substack.com/p/the-history-of-large-language-models 
20. Introducing Devin, the first AI software engineer, https://www.cognition-labs.com/introducing-devin 
21. A Conversation with the Founder of NVIDIA: Who Will Shape the Future of AI? https://www.youtube.com/watch?v=8Pm2xEViNIo 
22. The Race is On: Google and Microsoft Compete Over Large Language Models with ChatGPT, https://medium.com/@suruchi.hr/the-race-is-on-google-and-microsoft-compete-over-large-language-models-with-chatgpt-5a63165f24c8 
23. Apple is reportedly exploring a partnership with Google for Gemini-powered feature on iPhones, https://techcrunch.com/2024/03/17/apple-is-reportedly-exploring-a-partnership-with-google-for-gemini-powered-feature-on-iphones/ 
24. Outrageously Large Neural Networks: The Sparsely Gated Mixture-of-Experts Layer, https://arxiv.org/abs/1701.06538 



<!-- <br><br>

### Appendix

_The complete timeline:_

<img src="/assets/blogs/llm-olympics/LLM OLYMPICS.svg"/> -->